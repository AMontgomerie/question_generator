{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QG_T5_training.ipynb","provenance":[{"file_id":"1fjUac5wqsbl4kdfR6XRD0Zor3TfAg-fe","timestamp":1592456064028},{"file_id":"1y_8MTWmQnKalcdTQNLSZaoWN2KuAmUC5","timestamp":1591767629922},{"file_id":"1CIlJj2br71COiwuF4ZLWJPnMNgu0Z3u5","timestamp":1590466302923}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1Dv4wvUk6kl0WGFBxf2zb2W_3DDzwBLe8","authorship_tag":"ABX9TyOQ4kyEp8Tdy5y4dCBGm9At"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FvBm_K5WnVj9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595302025907,"user_tz":-540,"elapsed":1964,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}}},"source":["import os\n","import sys\n","import math\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import spacy"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-zYwMCMySvj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":336},"executionInfo":{"status":"ok","timestamp":1595302028656,"user_tz":-540,"elapsed":4698,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"e4b6bc2e-420e-4848-d2e7-4e239f4bd2b3"},"source":["!pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UDaysJyJytAs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595302030893,"user_tz":-540,"elapsed":6926,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}}},"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzW_zmk2qFHG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595302030894,"user_tz":-540,"elapsed":6919,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"95dd4ecb-30f2-4661-aae8-c920fb004702"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using device: cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s-IgF44jMFPY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595302036203,"user_tz":-540,"elapsed":12220,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}}},"source":["PRETRAINED_MODEL = 't5-base'\n","DIR = \"/content/drive/My Drive/ml_hw/NLP/question_generator/\"\n","BATCH_SIZE = 4\n","SEQ_LENGTH = 512\n","\n","tokenizer = T5Tokenizer.from_pretrained(PRETRAINED_MODEL)\n","tokenizer.add_special_tokens(\n","    {'additional_special_tokens': ['<answer>', '<context>']}\n",")\n","\n","class QGDataset(Dataset):\n","    def __init__(self, csv):\n","        self.df = pd.read_csv(csv, engine='python')\n","\n","    def __len__(self):\n","         return len(self.df)\n","\n","    def __getitem__(self, idx):   \n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        row = self.df.iloc[idx, 1:]       \n","\n","        encoded_text = tokenizer(\n","            row['text'], \n","            pad_to_max_length=True, \n","            max_length=SEQ_LENGTH,\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","        encoded_text['input_ids'] = torch.squeeze(encoded_text['input_ids'])\n","        encoded_text['attention_mask'] = torch.squeeze(encoded_text['attention_mask'])\n","\n","        encoded_question = tokenizer(\n","            row['question'],\n","            pad_to_max_length=True,\n","            max_length=SEQ_LENGTH,\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","        encoded_question['input_ids'] = torch.squeeze(encoded_question['input_ids'])\n","\n","        return (encoded_text.to(device), encoded_question.to(device))\n","\n","train_set = QGDataset(os.path.join(DIR, 'qg_train_3.csv')) \n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n","valid_set = QGDataset(os.path.join(DIR, 'qg_valid_3.csv')) \n","valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJrb9kYNz_wz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1595302063277,"user_tz":-540,"elapsed":11480,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}},"outputId":"fe296630-f0e6-40e7-a8bc-6ddddf3b861c"},"source":["LR = 0.001\n","EPOCHS = 20\n","LOG_INTERVAL = 5000\n","\n","config = T5Config(decoder_start_token_id=tokenizer.pad_token_id)\n","model = T5ForConditionalGeneration(config).from_pretrained(PRETRAINED_MODEL)\n","model.resize_token_embeddings(len(tokenizer)) # to account for new special tokens\n","model = model.to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Some weights of T5ForConditionalGeneration were not initialized from the model checkpoint at t5-base and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rcfRh2JC0CF1","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595302064086,"user_tz":-540,"elapsed":793,"user":{"displayName":"Adam Montgomerie","photoUrl":"","userId":"08195438125971362273"}}},"source":["SAVED_MODEL_PATH = \"/content/drive/My Drive/ml_hw/NLP/question_generator/qg_pretrained_t5_model_trained_3.pth\"\n","TEMP_SAVE_PATH = \"/content/drive/My Drive/ml_hw/NLP/question_generator/qg_pretrained_t5_model_trained_3_TEMP.pth\"\n","\n","def train(epoch, best_val_loss):\n","    model.train()\n","    total_loss = 0.\n","    for batch_index, batch in enumerate(train_loader):\n","        data, target = batch\n","        optimizer.zero_grad()\n","        masked_labels = mask_label_padding(target['input_ids'])\n","        output = model(\n","            input_ids=data['input_ids'],\n","            attention_mask=data['attention_mask'],\n","            lm_labels=masked_labels\n","        )\n","        loss = output[0]\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        if batch_index % LOG_INTERVAL == 0 and batch_index > 0:\n","            cur_loss = total_loss / LOG_INTERVAL\n","            print('| epoch {:3d} | ' \n","                  '{:5d}/{:5d} batches | '\n","                  'loss {:5.2f}'.format(\n","                    epoch, \n","                    batch_index, len(train_loader), \n","                    cur_loss))\n","            save(\n","                TEMP_SAVE_PATH,\n","                epoch, \n","                model.state_dict(), \n","                optimizer.state_dict(), \n","                best_val_loss\n","            )\n","            total_loss = 0\n","\n","def evaluate(eval_model, data_loader):\n","    eval_model.eval()\n","    total_loss = 0.\n","    with torch.no_grad():\n","        for batch_index, batch in enumerate(data_loader):\n","            data, target = batch\n","            masked_labels = mask_label_padding(target['input_ids'])\n","            output = eval_model(\n","                input_ids=data['input_ids'],\n","                attention_mask=data['attention_mask'],\n","                lm_labels=masked_labels\n","            )\n","            total_loss += output[0].item()\n","    return total_loss / len(data_loader)\n","\n","def generate_attention_mask(input_ids):\n","    # 0 for masked tokens, 1 for not masked tokens\n","    mask = torch.where(\n","        input_ids.cpu() == torch.full(input_ids.size(), tokenizer.pad_token_id, dtype=int),\n","        torch.zeros(input_ids.size()), \n","        torch.ones(input_ids.size())\n","    )\n","    return mask.to(device)\n","\n","def mask_label_padding(labels):\n","    MASK_ID = -100\n","    labels[labels==tokenizer.pad_token_id] = MASK_ID\n","    return labels\n","\n","def save(path, epoch, model_state_dict, optimizer_state_dict, loss):\n","    torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model_state_dict,\n","            'optimizer_state_dict': optimizer_state_dict,\n","            'best_loss': loss,\n","            }, path)\n","\n","    print(\"| Model saved.\")\n","    print_line()\n","\n","def load(path):\n","    return torch.load(path)\n","\n","def print_line():\n","    LINE_WIDTH = 60\n","    print('-' * LINE_WIDTH)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"9J13rDps2QIu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"1de59c13-b147-470c-fecc-8e1328f9fd83"},"source":["best_val_loss = float(\"inf\")\n","best_model = None\n","\n","val_loss = evaluate(model, valid_loader)\n","print_line()\n","print('| Before training | valid loss {:5.2f}'.format(\n","    val_loss)\n",")\n","print_line()\n","\n","for epoch in range(1, EPOCHS + 1):\n","\n","    train()\n","    val_loss = evaluate(model, valid_loader)\n","    print_line()\n","    print('| end of epoch {:3d} | valid loss {:5.2f}'.format(\n","        epoch,\n","        val_loss)\n","    )\n","    print_line()\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = model\n","        save(\n","             SAVED_MODEL_PATH,\n","             epoch, \n","             model.state_dict(), \n","             optimizer.state_dict(), \n","             best_val_loss\n","        )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["------------------------------------------------------------\n","| Before training | valid loss  5.68\n","------------------------------------------------------------\n","| epoch   1 |  1000/51003 batches | loss  4.34\n","| epoch   1 |  2000/51003 batches | loss  3.61\n","| epoch   1 |  3000/51003 batches | loss  3.52\n","| epoch   1 |  4000/51003 batches | loss  3.41\n","| epoch   1 |  5000/51003 batches | loss  3.38\n","| epoch   1 |  6000/51003 batches | loss  3.33\n","| epoch   1 |  7000/51003 batches | loss  3.32\n","| epoch   1 |  8000/51003 batches | loss  3.26\n","| epoch   1 |  9000/51003 batches | loss  3.20\n","| epoch   1 | 10000/51003 batches | loss  3.18\n","| epoch   1 | 11000/51003 batches | loss  3.13\n","| epoch   1 | 12000/51003 batches | loss  3.09\n","| epoch   1 | 13000/51003 batches | loss  3.08\n","| epoch   1 | 14000/51003 batches | loss  3.03\n","| epoch   1 | 15000/51003 batches | loss  3.01\n","| epoch   1 | 16000/51003 batches | loss  2.97\n","| epoch   1 | 17000/51003 batches | loss  2.96\n","| epoch   1 | 18000/51003 batches | loss  2.88\n","| epoch   1 | 19000/51003 batches | loss  2.86\n","| epoch   1 | 20000/51003 batches | loss  2.84\n","| epoch   1 | 21000/51003 batches | loss  2.81\n","| epoch   1 | 22000/51003 batches | loss  2.74\n","| epoch   1 | 23000/51003 batches | loss  2.73\n","| epoch   1 | 24000/51003 batches | loss  2.70\n","| epoch   1 | 25000/51003 batches | loss  2.72\n","| epoch   1 | 26000/51003 batches | loss  2.72\n","| epoch   1 | 27000/51003 batches | loss  2.71\n","| epoch   1 | 28000/51003 batches | loss  2.71\n","| epoch   1 | 29000/51003 batches | loss  2.71\n","| epoch   1 | 30000/51003 batches | loss  2.65\n","| epoch   1 | 31000/51003 batches | loss  2.64\n","| epoch   1 | 32000/51003 batches | loss  2.62\n","| epoch   1 | 33000/51003 batches | loss  2.61\n","| epoch   1 | 34000/51003 batches | loss  2.64\n","| epoch   1 | 35000/51003 batches | loss  2.62\n","| epoch   1 | 36000/51003 batches | loss  2.61\n","| epoch   1 | 37000/51003 batches | loss  2.61\n","| epoch   1 | 38000/51003 batches | loss  2.59\n","| epoch   1 | 39000/51003 batches | loss  2.56\n","| epoch   1 | 40000/51003 batches | loss  2.57\n","| epoch   1 | 41000/51003 batches | loss  2.57\n","| epoch   1 | 42000/51003 batches | loss  2.57\n","| epoch   1 | 43000/51003 batches | loss  2.57\n","| epoch   1 | 44000/51003 batches | loss  2.55\n","| epoch   1 | 45000/51003 batches | loss  2.54\n","| epoch   1 | 46000/51003 batches | loss  2.56\n","| epoch   1 | 47000/51003 batches | loss  2.55\n","| epoch   1 | 48000/51003 batches | loss  2.52\n","| epoch   1 | 49000/51003 batches | loss  2.49\n","| epoch   1 | 50000/51003 batches | loss  2.53\n","| epoch   1 | 51000/51003 batches | loss  2.51\n","------------------------------------------------------------\n","| end of epoch   1 | valid loss  2.28\n","------------------------------------------------------------\n","| Model saved.\n","------------------------------------------------------------\n","| epoch   2 |  1000/51003 batches | loss  2.50\n","| epoch   2 |  2000/51003 batches | loss  2.50\n","| epoch   2 |  3000/51003 batches | loss  2.50\n","| epoch   2 |  4000/51003 batches | loss  2.49\n","| epoch   2 |  5000/51003 batches | loss  2.48\n","| epoch   2 |  6000/51003 batches | loss  2.46\n","| epoch   2 |  7000/51003 batches | loss  2.49\n","| epoch   2 |  8000/51003 batches | loss  2.48\n","| epoch   2 |  9000/51003 batches | loss  2.44\n","| epoch   2 | 10000/51003 batches | loss  2.48\n","| epoch   2 | 11000/51003 batches | loss  2.43\n","| epoch   2 | 12000/51003 batches | loss  2.45\n","| epoch   2 | 13000/51003 batches | loss  2.47\n","| epoch   2 | 14000/51003 batches | loss  2.43\n","| epoch   2 | 15000/51003 batches | loss  2.43\n","| epoch   2 | 16000/51003 batches | loss  2.42\n","| epoch   2 | 17000/51003 batches | loss  2.46\n","| epoch   2 | 18000/51003 batches | loss  2.43\n","| epoch   2 | 19000/51003 batches | loss  2.43\n","| epoch   2 | 20000/51003 batches | loss  2.42\n","| epoch   2 | 21000/51003 batches | loss  2.44\n","| epoch   2 | 22000/51003 batches | loss  2.40\n","| epoch   2 | 23000/51003 batches | loss  2.38\n","| epoch   2 | 24000/51003 batches | loss  2.41\n","| epoch   2 | 25000/51003 batches | loss  2.40\n","| epoch   2 | 26000/51003 batches | loss  2.42\n","| epoch   2 | 27000/51003 batches | loss  2.41\n","| epoch   2 | 28000/51003 batches | loss  2.39\n","| epoch   2 | 29000/51003 batches | loss  2.38\n","| epoch   2 | 30000/51003 batches | loss  2.42\n","| epoch   2 | 31000/51003 batches | loss  2.35\n","| epoch   2 | 32000/51003 batches | loss  2.40\n","| epoch   2 | 33000/51003 batches | loss  2.38\n","| epoch   2 | 34000/51003 batches | loss  2.37\n","| epoch   2 | 35000/51003 batches | loss  2.39\n","| epoch   2 | 36000/51003 batches | loss  2.32\n","| epoch   2 | 37000/51003 batches | loss  2.37\n","| epoch   2 | 38000/51003 batches | loss  2.35\n","| epoch   2 | 39000/51003 batches | loss  2.35\n","| epoch   2 | 40000/51003 batches | loss  2.33\n","| epoch   2 | 41000/51003 batches | loss  2.33\n","| epoch   2 | 42000/51003 batches | loss  2.35\n","| epoch   2 | 43000/51003 batches | loss  2.32\n","| epoch   2 | 44000/51003 batches | loss  2.32\n","| epoch   2 | 45000/51003 batches | loss  2.32\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sny2VpY9rx78","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"outputId":"e2c6185a-f4ba-4f90-f619-777dc39d3f0b"},"source":["# let's re-load the model and continue training.\n","# it timed out mid-epoch so we're going to save more regularly\n","\n","checkpoint = load(SAVED_MODEL_PATH)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","current_epoch = checkpoint['epoch']\n","best_val_loss = checkpoint['best_loss']\n","model.to(device)\n","\n","for epoch in range(current_epoch + 1, EPOCHS + 1):\n","\n","    train(epoch, best_val_loss)\n","    val_loss = evaluate(model, valid_loader)\n","    print_line()\n","    print('| end of epoch {:3d} | valid loss {:5.2f}'.format(\n","        epoch,\n","        val_loss)\n","    )\n","    print_line()\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        save(\n","            epoch, \n","             model.state_dict(), \n","             optimizer.state_dict(), \n","             best_val_loss\n","        )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["| epoch   2 |  5000/51003 batches | loss  2.48\n","| Model saved.\n","------------------------------------------------------------\n","| epoch   2 | 10000/51003 batches | loss  2.47\n","| Model saved.\n","------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"obR6RD9cjJnU","colab_type":"code","colab":{}},"source":["#let's re-load the model and continue training AGAIN.\n","\n","checkpoint = load()\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","current_epoch = checkpoint['epoch']\n","best_val_loss = checkpoint['best_loss']\n","model.to(device)\n","\n","additional_epochs = EPOCHS + 5\n","\n","for epoch in range(current_epoch + 1, additional_epochs + 1):\n","\n","    train()\n","    val_loss = evaluate(model, valid_loader)\n","    print_line()\n","    print('| end of epoch {:3d} | valid loss {:5.2f}'.format(\n","        epoch,\n","        val_loss)\n","    )\n","    print_line()\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        save(\n","            epoch, \n","             model.state_dict(), \n","             optimizer.state_dict(), \n","             best_val_loss\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eW1-e7BIAeWe","colab_type":"code","colab":{}},"source":["#let's re-load the model and continue training AGAIN AGAIN\n","\n","checkpoint = load()\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","current_epoch = checkpoint['epoch']\n","best_val_loss = checkpoint['best_loss']\n","model.to(device)\n","\n","additional_epochs = EPOCHS + 5\n","\n","for epoch in range(current_epoch + 1, additional_epochs + 1):\n","\n","    train()\n","    val_loss = evaluate(model, valid_loader)\n","    print_line()\n","    print('| end of epoch {:3d} | valid loss {:5.2f}'.format(\n","        epoch,\n","        val_loss)\n","    )\n","    print_line()\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        save(\n","            epoch, \n","             model.state_dict(), \n","             optimizer.state_dict(), \n","             best_val_loss\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WPQ3ciAL6QYl","colab_type":"code","colab":{}},"source":["#let's re-load the model and continue training AGAIN AGAIN AGAIN (last time I promise)\n","\n","checkpoint = load()\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","current_epoch = checkpoint['epoch']\n","best_val_loss = checkpoint['best_loss']\n","model.to(device)\n","\n","additional_epochs = EPOCHS + 10\n","\n","for epoch in range(current_epoch + 1, additional_epochs + 1):\n","\n","    train()\n","    val_loss = evaluate(model, valid_loader)\n","    print_line()\n","    print('| end of epoch {:3d} | valid loss {:5.2f}'.format(\n","        epoch,\n","        val_loss)\n","    )\n","    print_line()\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        save(\n","            epoch, \n","             model.state_dict(), \n","             optimizer.state_dict(), \n","             best_val_loss\n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gecArC3SPmO2","colab_type":"code","colab":{}},"source":["checkpoint = load()\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(device)\n","\n","model.eval()\n","total_loss = 0.\n","with torch.no_grad():\n","    i = 0\n","    for batch_index, batch in enumerate(valid_loader):\n","        data, target = batch\n","        masked_labels = mask_label_padding(target['input_ids'])\n","        output = model.generate(input_ids=data['input_ids'])\n","        print(tokenizer.decode(output[0]))\n","        print(tokenizer.decode(data['input_ids'][0]))\n","        i += 1\n","        if i >= 10:\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"olyGLLg3ViP0","colab_type":"code","colab":{}},"source":["checkpoint = load()\n","model.load_state_dict(checkpoint['model_state_dict'])\n","model.to(device)\n","\n","inputs = [\n","      '<answer> The US virus death toll has surpassed 50,000 <context> The US virus death toll has surpassed 50,000, according to data from Johns Hopkins University.',\n","      '<answer> in the last 24 hours <context> More than 3,000 deaths came in the last 24 hours, and there are now over 870,000 confirmed cases nationwide.',\n","      '<answer> The US <context> The US still has a lower mortality rate than most European nations based on current case counts.'    \n","]\n","\n","for input_text in inputs:\n","    encoded_input = tokenizer(input_text, return_tensors='pt').to(device)\n","    output = model.generate(input_ids=encoded_input['input_ids'])\n","    print(tokenizer.decode(output[0]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"K3mqDpzJGn6Z","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}