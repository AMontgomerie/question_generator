{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"QG_T5_training.ipynb","provenance":[{"file_id":"1fjUac5wqsbl4kdfR6XRD0Zor3TfAg-fe","timestamp":1592456064028},{"file_id":"1y_8MTWmQnKalcdTQNLSZaoWN2KuAmUC5","timestamp":1591767629922},{"file_id":"1CIlJj2br71COiwuF4ZLWJPnMNgu0Z3u5","timestamp":1590466302923}],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1Dv4wvUk6kl0WGFBxf2zb2W_3DDzwBLe8","authorship_tag":"ABX9TyNkFJbYAaLQ9Q2ylMwrLSAk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FvBm_K5WnVj9","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import math\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import spacy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B-zYwMCMySvj","colab_type":"code","colab":{}},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UDaysJyJytAs","colab_type":"code","colab":{}},"source":["from transformers import T5Tokenizer, T5ForConditionalGeneration, T5Config"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzW_zmk2qFHG","colab_type":"code","colab":{}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s-IgF44jMFPY","colab_type":"code","colab":{}},"source":["PRETRAINED_MODEL = 't5-base'\n","DIR = \"question_generator/\"\n","BATCH_SIZE = 4\n","SEQ_LENGTH = 512\n","\n","tokenizer = T5Tokenizer.from_pretrained(PRETRAINED_MODEL)\n","tokenizer.add_special_tokens(\n","    {'additional_special_tokens': ['<answer>', '<context>']}\n",")\n","\n","class QGDataset(Dataset):\n","    def __init__(self, csv):\n","        self.df = pd.read_csv(csv, engine='python')\n","\n","    def __len__(self):\n","         return len(self.df)\n","\n","    def __getitem__(self, idx):   \n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        row = self.df.iloc[idx, 1:]       \n","\n","        encoded_text = tokenizer(\n","            row['text'], \n","            pad_to_max_length=True, \n","            max_length=SEQ_LENGTH,\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","        encoded_text['input_ids'] = torch.squeeze(encoded_text['input_ids'])\n","        encoded_text['attention_mask'] = torch.squeeze(encoded_text['attention_mask'])\n","\n","        encoded_question = tokenizer(\n","            row['question'],\n","            pad_to_max_length=True,\n","            max_length=SEQ_LENGTH,\n","            truncation=True,\n","            return_tensors='pt'\n","        )\n","        encoded_question['input_ids'] = torch.squeeze(encoded_question['input_ids'])\n","\n","        return (encoded_text.to(device), encoded_question.to(device))\n","\n","train_set = QGDataset(os.path.join(DIR, 'question_generator/datasets/qg_train.csv'))\n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n","valid_set = QGDataset(os.path.join(DIR, 'question_generator/datasets/qg_valid.csv')) \n","valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NJrb9kYNz_wz","colab_type":"code","colab":{}},"source":["LR = 0.001\n","EPOCHS = 20\n","LOG_INTERVAL = 5000\n","\n","config = T5Config(decoder_start_token_id=tokenizer.pad_token_id)\n","model = T5ForConditionalGeneration(config).from_pretrained(PRETRAINED_MODEL)\n","model.resize_token_embeddings(len(tokenizer)) # to account for new special tokens\n","model = model.to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcfRh2JC0CF1","colab_type":"code","colab":{}},"source":["SAVED_MODEL_PATH = \"question_generator/qg_pretrained_t5_model_trained.pth\"\n","\n","def train(epoch, best_val_loss):\n","    model.train()\n","    total_loss = 0.\n","    for batch_index, batch in enumerate(train_loader):\n","        data, target = batch\n","        optimizer.zero_grad()\n","        masked_labels = mask_label_padding(target['input_ids'])\n","        output = model(\n","            input_ids=data['input_ids'],\n","            attention_mask=data['attention_mask'],\n","            lm_labels=masked_labels\n","        )\n","        loss = output[0]\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","\n","        total_loss += loss.item()\n","        if batch_index % LOG_INTERVAL == 0 and batch_index > 0:\n","            cur_loss = total_loss / LOG_INTERVAL\n","            print('| epoch {:3d} | ' \n","                  '{:5d}/{:5d} batches | '\n","                  'loss {:5.2f}'.format(\n","                    epoch, \n","                    batch_index, len(train_loader), \n","                    cur_loss))\n","            save(\n","                TEMP_SAVE_PATH,\n","                epoch, \n","                model.state_dict(), \n","                optimizer.state_dict(), \n","                best_val_loss\n","            )\n","            total_loss = 0\n","\n","def evaluate(eval_model, data_loader):\n","    eval_model.eval()\n","    total_loss = 0.\n","    with torch.no_grad():\n","        for batch_index, batch in enumerate(data_loader):\n","            data, target = batch\n","            masked_labels = mask_label_padding(target['input_ids'])\n","            output = eval_model(\n","                input_ids=data['input_ids'],\n","                attention_mask=data['attention_mask'],\n","                lm_labels=masked_labels\n","            )\n","            total_loss += output[0].item()\n","    return total_loss / len(data_loader)\n","\n","def mask_label_padding(labels):\n","    MASK_ID = -100\n","    labels[labels==tokenizer.pad_token_id] = MASK_ID\n","    return labels\n","\n","def save(path, epoch, model_state_dict, optimizer_state_dict, loss):\n","    torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model_state_dict,\n","            'optimizer_state_dict': optimizer_state_dict,\n","            'best_loss': loss,\n","            }, path)\n","\n","def load(path):\n","    return torch.load(path)\n","\n","def print_line():\n","    LINE_WIDTH = 60\n","    print('-' * LINE_WIDTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9J13rDps2QIu","colab_type":"code","colab":{}},"source":["best_val_loss = float(\"inf\")\n","best_model = None\n","\n","val_loss = evaluate(model, valid_loader)\n","print_line()\n","print('| Before training | valid loss {:5.2f}'.format(\n","    val_loss)\n",")\n","print_line()\n","\n","for epoch in range(1, EPOCHS + 1):\n","\n","    train()\n","    val_loss = evaluate(model, valid_loader)\n","    print_line()\n","    print('| end of epoch {:3d} | valid loss {:5.2f}'.format(\n","        epoch,\n","        val_loss)\n","    )\n","    print_line()\n","\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_model = model\n","        save(\n","             SAVED_MODEL_PATH,\n","             epoch, \n","             model.state_dict(), \n","             optimizer.state_dict(), \n","             best_val_loss\n","        )\n","        print(\"| Model saved.\")\n","        print_line()"],"execution_count":null,"outputs":[]}]}
