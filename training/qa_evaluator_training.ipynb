{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"qa_evaluator_training.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1emXX3VUG1HfrPUk65Tcyabxc_1I5nJhb","authorship_tag":"ABX9TyO+frNBr60urb4CDRgCiqFz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"zYh3QRoOX5pt","colab_type":"code","colab":{}},"source":["import os\n","import sys\n","import random\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rCrFsm-Ucw1L","colab_type":"code","colab":{}},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MoVZz2ipcyED","colab_type":"code","colab":{}},"source":["from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification\n","from transformers import BertConfig"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZ7-oYxKbShb","colab_type":"code","colab":{}},"source":["!pip install -U spacy[cuda92]\n","!python -m spacy download en_core_web_sm\n","import spacy\n","import en_core_web_sm\n","spacy.prefer_gpu()\n","spacy_nlp = en_core_web_sm.load()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lIW-LTWri3PT","colab_type":"code","colab":{}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print('Using device:', device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hqayKzYSc5tg","colab_type":"code","colab":{}},"source":["DIR = \"question_generator/\"\n","PRETRAINED_MODEL = 'bert-base-cased'\n","BATCH_SIZE = 16\n","SEQ_LENGTH = 512\n","\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL)\n","\n","class QAEvalDataset(Dataset):\n","    def __init__(self, csv):\n","        self.df = pd.read_csv(csv, engine='python')\n","        self.transforms = [self.shuffle, self.corrupt]\n","\n","    def __len__(self):\n","         return len(self.df)\n","\n","    def __getitem__(self, idx): \n","        _, question, answer = self.df.iloc[idx]\n","        label = random.choice([0, 1])\n","\n","        if label == 0:\n","            question, answer = random.choice(self.transforms)(question, answer)\n","\n","        encoded_data = tokenizer(\n","            text=question,\n","            text_pair=answer,\n","            pad_to_max_length=True, \n","            max_length=SEQ_LENGTH,\n","            truncation=True,\n","            return_tensors=\"pt\"\n","        )\n","\n","        encoded_data['input_ids'] = torch.squeeze(encoded_data['input_ids'])\n","        encoded_data['token_type_ids'] = torch.squeeze(encoded_data['token_type_ids'])\n","        encoded_data['attention_mask'] = torch.squeeze(encoded_data['attention_mask'])\n","        return (encoded_data.to(device), torch.tensor(label).to(device))\n","    \n","    def shuffle(self, question, answer):\n","        shuffled_answer = answer\n","        while shuffled_answer == answer:\n","            shuffled_answer = self.df.sample(1)['answer'].item()\n","        return question, shuffled_answer\n","    \n","    def corrupt(self, question, answer):\n","        doc = spacy_nlp(question)\n","        if len(doc.ents) > 1:\n","            # Replace all entities in the sentence with the same thing\n","            copy_ent = str(random.choice(doc.ents))\n","            for ent in doc.ents:\n","                question = question.replace(str(ent), copy_ent)\n","        elif len(doc.ents) == 1:\n","            # Replace the answer with an entity from the question\n","            answer = str(doc.ents[0])\n","        else:\n","            question, answer = self.shuffle(question, answer)\n","        return question, answer\n","\n","\n","train_set = QAEvalDataset(os.path.join(DIR, 'qa_eval_train.csv')) \n","train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n","valid_set = QAEvalDataset(os.path.join(DIR, 'qa_eval_valid.csv')) \n","valid_loader = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8E4jQkWdolsT","colab_type":"code","colab":{}},"source":["LR = 0.001\n","EPOCHS = 10\n","LOG_INTERVAL = 500\n","\n","model = BertForSequenceClassification.from_pretrained(PRETRAINED_MODEL)\n","model = model.to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=LR)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CKcR_AClq6IG","colab_type":"code","colab":{}},"source":["SAVED_MODEL_PATH = \"question_generator/qa_eval_model_trained.pth\"\n","\n","def train():\n","    model.train()\n","    total_loss = 0.\n","    for batch_index, batch in enumerate(train_loader):\n","        data, labels = batch\n","        optimizer.zero_grad()\n","        output = model(**data, labels=labels)\n","        loss = output[0]\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n","        optimizer.step()\n","        total_loss += loss.item()\n","        \n","        if batch_index % LOG_INTERVAL == 0 and batch_index > 0:\n","            cur_loss = total_loss / LOG_INTERVAL\n","            print('| epoch {:3d} | ' \n","                  '{:5d}/{:5d} batches | '\n","                  'loss {:5.2f}'.format(\n","                    epoch, \n","                    batch_index, len(train_loader), \n","                    cur_loss))\n","            total_loss = 0\n","\n","def evaluate(eval_model, data_loader):\n","    eval_model.eval()\n","    total_score = 0.\n","    with torch.no_grad():\n","        for batch_index, batch in enumerate(data_loader):\n","            data, labels = batch\n","            output = eval_model(**data, labels=labels)\n","            preds = np.argmax(output[1].cpu(), axis=1)\n","            total_score += (preds == labels.cpu()).sum()\n","    return total_score / (len(data_loader) * BATCH_SIZE)\n","\n","def save(epoch, model_state_dict, optimizer_state_dict, loss):\n","    torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model_state_dict,\n","            'optimizer_state_dict': optimizer_state_dict,\n","            'best_loss': loss,\n","            }, SAVED_MODEL_PATH)\n","\n","    print(\"| Model saved.\")\n","    print_line()\n","\n","def load():\n","    return torch.load(SAVED_MODEL_PATH)\n","\n","def print_line():\n","    LINE_WIDTH = 60\n","    print('-' * LINE_WIDTH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGzxEzlPjjwp","colab_type":"code","colab":{}},"source":["highest_accuracy = 0\n","\n","accuracy = evaluate(model, valid_loader)\n","print_line()\n","print('| Before training | accuracy on valid set: {:5.2f}%'.format(accuracy))\n","print_line()\n","\n","for epoch in range(1, EPOCHS + 1):\n","\n","    train()\n","    accuracy = evaluate(model, valid_loader)\n","    print_line()\n","    print('| end of epoch {:3d} | accuracy on valid set: {:5.2f}%'.format(\n","        epoch,\n","        accuracy)\n","    )\n","    print_line()\n","\n","    if accuracy > highest_accuracy:\n","        highest_accuracy = accuracy\n","        save(\n","             epoch, \n","             model.state_dict(), \n","             optimizer.state_dict(), \n","             highest_accuracy\n","        )"],"execution_count":null,"outputs":[]}]}
